{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/Montage/bin\n",
      "\n",
      "    ERROR: Montage commands could not be found.\n",
      "\n",
      "    In order to use the montage_wrapper module, you will first need to\n",
      "    install the IPAC Montage software from:\n",
      "\n",
      "        http://montage.ipac.caltech.edu\n",
      "\n",
      "    and ensure that the Montage commands (e.g. mAdd, mProject, etc.) are in\n",
      "    your $PATH. Your current $PATH variable contains the following paths,\n",
      "    but none of them contain the Montage commands:\n",
      "\n",
      "        PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:\n",
      "           /Montage/bin\n",
      "\n",
      "    If the Montage commands are in one of these directories, then please\n",
      "    report this as an issue with montage-wrapper.\n",
      "    \n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: Edward J Kim <edward.junhyung.kim@gmail.com>\n",
    "This script\n",
    " \n",
    "- Makes an SQL query to the SDSS DR12 database (using its API at\n",
    "  http://skyserver.sdss.org/dr12/en/help/docs/api.aspx) to create a catalog, \n",
    "- Downloads the FITS files,\n",
    "- Uses Montage (http://montage.ipac.caltech.edu/) and\n",
    "  montage wrapper (http://www.astropy.org/montage-wrapper/) to align each image\n",
    "  to the image in the r-band, and\n",
    "- Uses Sextractor (http://www.astromatic.net/software/sextractor) to find the\n",
    "  pixel position of objects, and\n",
    "- Converts the fluxes in FITS files to luptitudes\n",
    "  (http://www.sdss.org/dr12/algorithms/magnitudes/#asinh).\n",
    " \n",
    "See Dockerfile at https://github.com/EdwardJKim/deeplearning4astro/tree/master/docker.\n",
    "It has all packages necessary to run this notebook.\n",
    "To use this script with CasJobs, see\n",
    "https://github.com/EdwardJKim/dl4astro/blob/master/scripts/README.md.\n",
    "'''\n",
    "%env PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/Montage/bin\n",
    "                        \n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import json\n",
    "import bz2\n",
    "import re\n",
    "import subprocess\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpi4py import MPI\n",
    "\n",
    "import montage_wrapper as mw\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "\n",
    "\n",
    "def fetch_fits(df, dirname=\"../data/temp\"):\n",
    "\n",
    "    bands = [c for c in 'ugriz']\n",
    "\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "    for i, r in df.iterrows():\n",
    "\n",
    "        url = \"http://data.sdss3.org/sas/dr12/boss/photoObj/frames/{0}/{1}/{2}/\".format(\n",
    "            r[\"rerun\"], r[\"run\"], r[\"camcol\"], r[\"field\"])\n",
    "\n",
    "        for band in bands:\n",
    "\n",
    "            filename = \"frame-{4}-{1:06d}-{2}-{3:04d}.fits\".format(\n",
    "                r[\"rerun\"], r[\"run\"], r[\"camcol\"], r[\"field\"], band)\n",
    "            filepath = os.path.join(dirname, filename)\n",
    "\n",
    "            for _ in range(10):\n",
    "                try:\n",
    "                    resp = requests.get(url + filename + \".bz2\")\n",
    "                except:\n",
    "                    sleep(1)\n",
    "                    continue\n",
    "                \n",
    "                if resp.status_code == 200:\n",
    "                    with open(filepath, \"wb\") as f:\n",
    "                        img = bz2.decompress(resp.content)\n",
    "                        f.write(img)\n",
    "                    #print(\"Downloaded {}\".format(filename))\n",
    "                    break\n",
    "                else:\n",
    "                    sleep(1)\n",
    "                    continue\n",
    "\n",
    "            if not os.path.exists(filepath):\n",
    "                raise Exception\n",
    "\n",
    "def get_ref_list(df):\n",
    "\n",
    "    ref_images = []\n",
    "    \n",
    "    for row in df.iterrows():\n",
    "        r = row[1]\n",
    "        filename = \"frame-r-{1:06d}-{2}-{3:04d}.fits\".format(r[\"rerun\"], r[\"run\"], r[\"camcol\"], r[\"field\"])\n",
    "        ref_images.append(filename)\n",
    "\n",
    "    return ref_images\n",
    "\n",
    "def align_images(images, frame_dir=\"../data/temp\", registered_dir=\"../data/temp\"):\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    if not os.path.exists(registered_dir):\n",
    "        os.makedirs(registered_dir)\n",
    "    \n",
    "    for image in images:\n",
    "        \n",
    "        #print(\"Processing {}...\".format(image))\n",
    "    \n",
    "        frame_path = [\n",
    "            os.path.join(frame_dir, image.replace(\"frame-r-\", \"frame-{}-\").format(b))\n",
    "            for b in \"ugriz\"\n",
    "            ]\n",
    "        registered_path = [\n",
    "            os.path.join(registered_dir, image.replace(\"frame-r-\", \"registered-{}-\").format(b))\n",
    "            for b in \"ugriz\"\n",
    "            ]\n",
    "\n",
    "        header = os.path.join(\n",
    "            registered_dir,\n",
    "            image.replace(\"frame\", \"header\").replace(\".fits\", \".hdr\")\n",
    "            )\n",
    "\n",
    "        mw.commands.mGetHdr(os.path.join(frame_dir, image), header)\n",
    "        mw.reproject(\n",
    "            frame_path, registered_path,\n",
    "            header=header, exact_size=True, silent_cleanup=True, common=True\n",
    "            )\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def convert_catalog_to_pixels(df, dirname=\"../data/temp\"):\n",
    "\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "    pixels = []\n",
    "    fits_list = []\n",
    "\n",
    "    for i, r in df.iterrows():\n",
    "\n",
    "        fits_file = \"registered-r-{1:06d}-{2}-{3:04d}.fits\".format(\n",
    "            r[\"rerun\"], r[\"run\"], r[\"camcol\"], r[\"field\"])\n",
    "        fits_path = os.path.join(dirname, fits_file)\n",
    "            \n",
    "        hdulist = fits.open(fits_path)\n",
    "\n",
    "        w = wcs.WCS(hdulist[0].header, relax=False)\n",
    "        \n",
    "        px, py = w.all_world2pix(r[\"ra\"], r[\"dec\"], 1)\n",
    "\n",
    "        fits_list.append(fits_file)\n",
    "        pixels.append((i, px, py, r[\"class\"]))\n",
    "\n",
    "    for i, fits_file in enumerate(fits_list):\n",
    "        ix, px, py, c = pixels[i]\n",
    "        pixel_list = fits_file.replace(\".fits\", \".list\")\n",
    "        pixel_path = os.path.join(dirname, pixel_list)\n",
    "        with open(pixel_path, \"a\") as fout:\n",
    "            fout.write(\"{} {} {} {}\\n\".format(ix, px, py, c))\n",
    "\n",
    "    return None\n",
    "\n",
    "def write_default_conv():\n",
    "\n",
    "    default_conv = (\n",
    "        \"CONV NORM\\n\"\n",
    "        \"# 3x3 ``all-ground'' convolution mask with FWHM = 2 pixels.\\n\"\n",
    "        \"1 2 1\\n\"\n",
    "        \"2 4 2\\n\"\n",
    "        \"1 2 1\\n\"\n",
    "    ).format()\n",
    "\n",
    "    with open(\"default.conv\", \"w\") as f:\n",
    "        f.write(default_conv)\n",
    "\n",
    "    return None\n",
    "\n",
    "def write_default_param():\n",
    "\n",
    "    default_param = (\n",
    "        \"XMIN_IMAGE               Minimum x-coordinate among detected pixels                [pixel]\\n\"\n",
    "        \"YMIN_IMAGE               Minimum y-coordinate among detected pixels                [pixel]\\n\"\n",
    "        \"XMAX_IMAGE               Maximum x-coordinate among detected pixels                [pixel]\\n\"\n",
    "        \"YMAX_IMAGE               Maximum y-coordinate among detected pixels                [pixel]\\n\"\n",
    "        \"VECTOR_ASSOC(1)          #ASSOCiated parameter vector\"\n",
    "    ).format()\n",
    "\n",
    "    with open(\"default.param\", \"w\") as f:\n",
    "        f.write(default_param)\n",
    "\n",
    "    return None\n",
    "\n",
    "def write_default_sex():\n",
    "\n",
    "    default_sex = (\n",
    "        \"#-------------------------------- Catalog ------------------------------------\\n\"\n",
    "        \"\\n\"\n",
    "        \"CATALOG_NAME     test.cat       # name of the output catalog\\n\"\n",
    "        \"CATALOG_TYPE     ASCII_HEAD     # NONE,ASCII,ASCII_HEAD, ASCII_SKYCAT,\\n\"\n",
    "        \"                                # ASCII_VOTABLE, FITS_1.0 or FITS_LDAC\\n\"\n",
    "        \"PARAMETERS_NAME  default.param  # name of the file containing catalog contents\\n\"\n",
    "        \" \\n\"\n",
    "        \"#------------------------------- Extraction ----------------------------------\\n\"\n",
    "        \" \\n\"\n",
    "        \"DETECT_TYPE      CCD            # CCD (linear) or PHOTO (with gamma correction)\\n\"\n",
    "        \"DETECT_MINAREA   3              # min. # of pixels above threshold\\n\"\n",
    "        \"DETECT_THRESH    1.5            # <sigmas> or <threshold>,<ZP> in mag.arcsec-2\\n\"\n",
    "        \"ANALYSIS_THRESH  1.5            # <sigmas> or <threshold>,<ZP> in mag.arcsec-2\\n\"\n",
    "        \" \\n\"\n",
    "        \"FILTER           Y              # apply filter for detection (Y or N)?\\n\"\n",
    "        \"FILTER_NAME      default.conv   # name of the file containing the filter\\n\"\n",
    "        \" \\n\"\n",
    "        \"DEBLEND_NTHRESH  32             # Number of deblending sub-thresholds\\n\"\n",
    "        \"DEBLEND_MINCONT  0.005          # Minimum contrast parameter for deblending\\n\"\n",
    "        \" \\n\"\n",
    "        \"CLEAN            Y              # Clean spurious detections? (Y or N)?\\n\"\n",
    "        \"CLEAN_PARAM      1.0            # Cleaning efficiency\\n\"\n",
    "        \" \\n\"\n",
    "        \"MASK_TYPE        CORRECT        # type of detection MASKing: can be one of\\n\"\n",
    "        \"                                # NONE, BLANK or CORRECT\\n\"\n",
    "        \"\\n\"\n",
    "        \"#------------------------------ Photometry -----------------------------------\\n\"\n",
    "        \" \\n\"\n",
    "        \"PHOT_APERTURES   5              # MAG_APER aperture diameter(s) in pixels\\n\"\n",
    "        \"PHOT_AUTOPARAMS  2.5, 3.5       # MAG_AUTO parameters: <Kron_fact>,<min_radius>\\n\"\n",
    "        \"PHOT_PETROPARAMS 2.0, 3.5       # MAG_PETRO parameters: <Petrosian_fact>,\\n\"\n",
    "        \"                                # <min_radius>\\n\"\n",
    "        \"\\n\"\n",
    "        \"SATUR_LEVEL      50000.0        # level (in ADUs) at which arises saturation\\n\"\n",
    "        \"SATUR_KEY        SATURATE       # keyword for saturation level (in ADUs)\\n\"\n",
    "        \" \\n\"\n",
    "        \"MAG_ZEROPOINT    0.0            # magnitude zero-point\\n\"\n",
    "        \"MAG_GAMMA        4.0            # gamma of emulsion (for photographic scans)\\n\"\n",
    "        \"GAIN             0.0            # detector gain in e-/ADU\\n\"\n",
    "        \"GAIN_KEY         GAIN           # keyword for detector gain in e-/ADU\\n\"\n",
    "        \"PIXEL_SCALE      1.0            # size of pixel in arcsec (0=use FITS WCS info)\\n\"\n",
    "        \" \\n\"\n",
    "        \"#------------------------- Star/Galaxy Separation ----------------------------\\n\"\n",
    "        \" \\n\"\n",
    "        \"SEEING_FWHM      1.2            # stellar FWHM in arcsec\\n\"\n",
    "        \"STARNNW_NAME     default.nnw    # Neural-Network_Weight table filename\\n\"\n",
    "        \" \\n\"\n",
    "        \"#------------------------------ Background -----------------------------------\\n\"\n",
    "        \" \\n\"\n",
    "        \"BACK_SIZE        64             # Background mesh: <size> or <width>,<height>\\n\"\n",
    "        \"BACK_FILTERSIZE  3              # Background filter: <size> or <width>,<height>\\n\"\n",
    "        \" \\n\"\n",
    "        \"BACKPHOTO_TYPE   GLOBAL         # can be GLOBAL or LOCAL\\n\"\n",
    "        \" \\n\"\n",
    "        \"#------------------------------ Check Image ----------------------------------\\n\"\n",
    "        \" \\n\"\n",
    "        \"CHECKIMAGE_TYPE  SEGMENTATION   # can be NONE, BACKGROUND, BACKGROUND_RMS,\\n\"\n",
    "        \"                                # MINIBACKGROUND, MINIBACK_RMS, -BACKGROUND,\\n\"\n",
    "        \"                                # FILTERED, OBJECTS, -OBJECTS, SEGMENTATION,\\n\"\n",
    "        \"                                # or APERTURES\\n\"\n",
    "        \"CHECKIMAGE_NAME  check.fits     # Filename for the check-image\\n\"\n",
    "        \" \\n\"\n",
    "        \"#--------------------- Memory (change with caution!) -------------------------\\n\"\n",
    "        \" \\n\"\n",
    "        \"MEMORY_OBJSTACK  3000           # number of objects in stack\\n\"\n",
    "        \"MEMORY_PIXSTACK  300000         # number of pixels in stack\\n\"\n",
    "        \"MEMORY_BUFSIZE   1024           # number of lines in buffer\\n\"\n",
    "        \" \\n\"\n",
    "        \"#----------------------------- Miscellaneous ---------------------------------\\n\"\n",
    "        \" \\n\"\n",
    "        \"VERBOSE_TYPE     QUIET          # can be QUIET, NORMAL or FULL\\n\"\n",
    "        \"HEADER_SUFFIX    .head          # Filename extension for additional headers\\n\"\n",
    "        \"WRITE_XML        N              # Write XML file (Y/N)?\\n\"\n",
    "        \"XML_NAME         sex.xml        # Filename for XML output\\n\"\n",
    "        \"\\n\"\n",
    "        \"#----------------------------- ASSOC parameters ---------------------------------\\n\"\n",
    "        \"\\n\"\n",
    "        \"ASSOC_NAME       sky.list       # name of the ASCII file to ASSOCiate, the expected pixel \\n\"\n",
    "        \"                                # coordinates list given as [id, xpos, ypos]\\n\"\n",
    "        \"ASSOC_DATA       1              # columns of the data to replicate (0=all), replicate id\\n\"\n",
    "        \"                                # of the object in the SExtractor output file\\n\"\n",
    "        \"ASSOC_PARAMS     2,3            # columns of xpos,ypos[,mag] in the expected pixel\\n\"\n",
    "        \"                                # coordinates list\\n\"\n",
    "        \"ASSOC_RADIUS     2.0            # cross-matching radius (pixels)\\n\"\n",
    "        \"ASSOC_TYPE       NEAREST        # ASSOCiation method: FIRST, NEAREST, MEAN,\\n\"\n",
    "        \"                                # MAG_MEAN, SUM, MAG_SUM, MIN or MAX\\n\"\n",
    "        \"ASSOCSELEC_TYPE  MATCHED        # ASSOC selection type: ALL, MATCHED or -MATCHED\\n\"\n",
    "    ).format()\n",
    "\n",
    "    with open(\"default.sex\", \"w\") as f:\n",
    "        f.write(default_sex)\n",
    "\n",
    "def run_sex(df, dirname=\"../data/temp\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    cat = pd.DataFrame()\n",
    "\n",
    "    ref_images = get_ref_list(df) \n",
    "    print(ref_images)\n",
    "    registered_all = [f.replace(\"frame-\", \"registered-\") for f in ref_images]\n",
    "    \n",
    "    for f in registered_all:\n",
    "        \n",
    "        fpath = os.path.join(dirname, f)\n",
    "        \n",
    "        list_file = f.replace(\".fits\", \".list\")\n",
    "        list_path = os.path.join(dirname, list_file)\n",
    "        print(list_path)\n",
    "        config_file = f.replace(\".fits\", \".sex\")\n",
    "        print(config_file)\n",
    "        with open(\"default.sex\", \"r\") as default:\n",
    "            with open(config_file, \"w\") as temp:\n",
    "                for line in default:\n",
    "                    line = re.sub(\n",
    "                        r\"^ASSOC_NAME\\s+sky.list\",\n",
    "                        \"ASSOC_NAME       {}\".format(list_file),\n",
    "                        line\n",
    "                    )\n",
    "                    temp.write(line)\n",
    "    \n",
    "        shutil.copy(list_path, os.getcwd())\n",
    "    \n",
    "        subprocess.call([\"sex\", \"-c\", config_file, fpath])\n",
    "\n",
    "        os.remove(config_file)\n",
    "    \n",
    "        try:\n",
    "            assoc = pd.read_csv(\n",
    "                \"test.cat\",\n",
    "                skiprows=5,\n",
    "                sep=\"\\s+\",\n",
    "                names=[\"xmin\", \"ymin\", \"xmax\", \"ymax\", \"match\"]\n",
    "            )\n",
    "            assoc[\"file\"] = f\n",
    "            cat = cat.append(assoc)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        os.remove(os.path.join(os.getcwd(), list_file))\n",
    "    \n",
    "    if len(cat) > 0:\n",
    "         cat[\"class\"] = df.ix[cat[\"match\"], \"class\"].values\n",
    "         cat[\"objID\"] = df.ix[cat[\"match\"], \"objID\"].values\n",
    "         cat[\"z\"] = df.ix[cat[\"match\"], \"z\"].values   #MY MODIFICATION\n",
    "    #cat = cat.reset_index(drop=True)\n",
    "\n",
    "    return cat\n",
    "\n",
    "def nanomaggie_to_luptitude(array, band):\n",
    "    '''\n",
    "    Converts nanomaggies (flux) to luptitudes (magnitude).\n",
    "    http://www.sdss.org/dr12/algorithms/magnitudes/#asinh\n",
    "    http://arxiv.org/abs/astro-ph/9903081\n",
    "    '''\n",
    "    b = {\n",
    "        'u': 1.4e-10,\n",
    "        'g': 0.9e-10,\n",
    "        'r': 1.2e-10,\n",
    "        'i': 1.8e-10,\n",
    "        'z': 7.4e-10\n",
    "    }\n",
    "    nanomaggie = array * 1.0e-9 # fluxes are in nanomaggies\n",
    "\n",
    "    luptitude = -2.5 / np.log(10) * (np.arcsinh((nanomaggie / (2 * b[band]))) + np.log(b[band]))\n",
    "    \n",
    "    return luptitude\n",
    "\n",
    "def save_cutout(df, cat, size=48, image_dir=\"../data/temp\", save_dir=\"../data/result_full\"):\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    saved = pd.DataFrame()\n",
    "\n",
    "    def find_position(xmin, xmax, cut_size, frame_size):\n",
    "        diff = 0.5 * ((xmax - xmin) - cut_size)\n",
    "        if xmin + diff < 0:\n",
    "            r = 0\n",
    "            l = r + cut_size\n",
    "        elif xmax + diff >= frame_size:\n",
    "            l = frame_size\n",
    "            r = l - cut_size\n",
    "        else:\n",
    "            r = int(xmin + diff)\n",
    "            l = r + cut_size\n",
    "        return r, l\n",
    "\n",
    "    for i, row in cat.iterrows():\n",
    "\n",
    "        array = np.zeros((5, size, size))\n",
    "        \n",
    "        y0, x0, y1, x1 = row[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
    "        matched = df[df[\"objID\"] == row.astype(\"object\")[\"objID\"]]\n",
    "        assert len(matched) == 1\n",
    "\n",
    "        for j, b in enumerate(\"ugriz\"):\n",
    "\n",
    "            fpath = os.path.join(image_dir, row[\"file\"])\n",
    "            image_data = fits.getdata(fpath.replace(\"-r-\", \"-{}-\".format(b)))\n",
    "            \n",
    "            extinction = matched[\"extinction_{}\".format(b)].values[0]\n",
    "\n",
    "            right, left = find_position(x0, x1, size, image_data.shape[0])\n",
    "            down, up = find_position(y0, y1, size, image_data.shape[1])\n",
    "\n",
    "            cut_out = image_data[right: left, down: up]\n",
    "        \n",
    "            if cut_out.shape[0] == size and cut_out.shape[1] == size:\n",
    "                cut_out = nanomaggie_to_luptitude(cut_out, b) - extinction\n",
    "                array[j, :, :] = cut_out\n",
    "                \n",
    "        if np.isnan(array).sum() == 0 and array.sum() > 0:\n",
    "            save_path = os.path.join(save_dir, \"{0}.{1}x{1}.{2}.npy\".format(row[\"class\"], size, row[\"objID\"]))\n",
    "            np.save(save_path, array)\n",
    "            \n",
    "            \n",
    "########MY MODIFICATION UPON SAVE_CUTOUT####            \n",
    "def save_Xy(df, cat, size=48, image_dir=\"../data/temp\", save_dir=\"../data/result_full\"):\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    saved = pd.DataFrame()\n",
    "\n",
    "    def find_position(xmin, xmax, cut_size, frame_size):\n",
    "        diff = 0.5 * ((xmax - xmin) - cut_size)\n",
    "        if xmin + diff < 0:\n",
    "            r = 0\n",
    "            l = r + cut_size\n",
    "        elif xmax + diff >= frame_size:\n",
    "            l = frame_size\n",
    "            r = l - cut_size\n",
    "        else:\n",
    "            r = int(xmin + diff)\n",
    "            l = r + cut_size\n",
    "        return r, l\n",
    "    \n",
    "    for i, row in cat.iterrows():\n",
    "        array = np.zeros((5, size, size))\n",
    "        \n",
    "        y0, x0, y1, x1 = row[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
    "        matched = df[df[\"objID\"] == row.astype(\"object\")[\"objID\"]]\n",
    "        assert len(matched) == 1\n",
    "        \n",
    "\n",
    "        for j, b in enumerate(\"ugriz\"):\n",
    "            fpath = os.path.join(image_dir, row[\"file\"])\n",
    "            image_data = fits.getdata(fpath.replace(\"-r-\", \"-{}-\".format(b)))\n",
    "            \n",
    "            extinction = matched[\"extinction_{}\".format(b)].values[0]\n",
    "\n",
    "            right, left = find_position(x0, x1, size, image_data.shape[0])\n",
    "            down, up = find_position(y0, y1, size, image_data.shape[1])\n",
    "\n",
    "            cut_out = image_data[right: left, down: up]\n",
    "          \n",
    "            if cut_out.shape[0] == size and cut_out.shape[1] == size:\n",
    "                cut_out = nanomaggie_to_luptitude(cut_out, b) - extinction\n",
    "                array[j, :, :] = cut_out\n",
    "                \n",
    "        if np.isnan(array).sum() == 0 and array.sum() > 0:\n",
    "        \n",
    "            save_path = os.path.join(save_dir, \"{0:.8f}.{1}x{1}.{2}.npy\".format(row[\"z\"], size, row[\"objID\"]))\n",
    "            np.save(save_path, array)    \n",
    "\n",
    "def run_online_mode(filename=\"DR12_spec_phot_sample.csv\", chunk_size=100):\n",
    "\n",
    "    df = pd.read_csv(filename, dtype={\"objID\": \"object\"})\n",
    "\n",
    "    if os.path.exists(\"../data/result_full\"):\n",
    "        done = os.listdir(\"../data/result_full\")\n",
    "        done = [d.split(\".\")[2] for d in done]\n",
    "        # check existing results and skip\n",
    "        df = df[~df.objID.isin(done)]\n",
    "\n",
    "    write_default_conv()\n",
    "    write_default_param()\n",
    "    write_default_sex()\n",
    "\n",
    "    for i in range(0, len(df), chunk_size):\n",
    "        chunk = df[i: i + chunk_size]\n",
    "        # download image fits files\n",
    "        fetch_fits(chunk)\n",
    "        print(\"Its so fetch\")\n",
    "        ref_images = get_ref_list(chunk)\n",
    "        print(\"A ref on the play\")\n",
    "        align_images(ref_images)\n",
    "        print(\"Invisalign has nothing on this\")\n",
    "        convert_catalog_to_pixels(chunk)\n",
    "        print(\"pretty pretty pixels\")\n",
    "        cat = run_sex(chunk)\n",
    "        print(\"so sexy\")\n",
    "        try:\n",
    "            #saved = save_cutout(chunk, cat, size=48)\n",
    "            saved = save_Xy(chunk, cat, size=48)\n",
    "            print(\"cut it out guys!\")\n",
    "        except:\n",
    "            pass\n",
    "        shutil.rmtree(\"../data/temp\")\n",
    "        print(\"{} objects remaining...\".format(len(df) - chunk_size - i))\n",
    "\n",
    "def run_parallel(filename, dest=None):\n",
    "\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "\n",
    "    if rank == 0:\n",
    "        print(\"Running on {} cores...\\n\".format(size))\n",
    "\n",
    "        write_default_conv()\n",
    "        write_default_param()\n",
    "        write_default_sex()\n",
    "\n",
    "    df = pd.read_csv(filename, dtype={\"objID\": \"object\"})\n",
    "\n",
    "    if os.path.exists(\"result\"):\n",
    "        done = os.listdir(\"result\")\n",
    "        done = [d.split(\".\")[2] for d in done]\n",
    "        # check existing results and skip\n",
    "        df = df[~df.objID.isin(done)].dropna()\n",
    "\n",
    "    start = int(rank / size * len(df))\n",
    "    end = int((rank + 1) / size * len(df))\n",
    "    df = df[start:end]\n",
    "\n",
    "    if dest is None:\n",
    "        dest = os.getcwd()\n",
    "    temp_dir = os.path.join(dest, \"temp{}\".format(rank))\n",
    "    target_dir = os.path.join(dest, \"result\".format(rank))\n",
    "\n",
    "    for i in range(0, len(df)):\n",
    "        chunk = df[i: i + 1]\n",
    "        try:\n",
    "            # download image fits files\n",
    "            fetch_fits(chunk, dirname=temp_dir)\n",
    "            ref_images = get_ref_list(chunk)\n",
    "            align_images(ref_images, frame_dir=temp_dir, registered_dir=temp_dir)\n",
    "            convert_catalog_to_pixels(chunk, dirname=temp_dir)\n",
    "            cat = run_sex(chunk, dirname=temp_dir)\n",
    "            saved = save_cutout(cat, image_dir=temp_dir, save_dir=target_dir)\n",
    "            shutil.rmtree(temp_dir)\n",
    "            print(\"Core {}: processing successful...\".format(rank))\n",
    "        except:\n",
    "            print(\"Core {} failed to process an object...\".format(rank))\n",
    "\n",
    "        print(\"Core {}: {} objects remaining...\".format(rank, len(df) - 1 - i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its so fetch\n",
      "A ref on the play\n",
      "Invisalign has nothing on this\n",
      "pretty pretty pixels\n",
      "['frame-r-005360-2-0181.fits', 'frame-r-002125-4-0114.fits', 'frame-r-005312-5-0096.fits', 'frame-r-001350-5-0151.fits', 'frame-r-001045-2-0147.fits', 'frame-r-002830-3-0363.fits', 'frame-r-001869-2-0078.fits', 'frame-r-002825-6-0176.fits', 'frame-r-003606-5-0041.fits', 'frame-r-003698-1-0134.fits', 'frame-r-003900-1-0599.fits', 'frame-r-003185-3-0031.fits', 'frame-r-007777-3-0080.fits', 'frame-r-003538-4-0209.fits', 'frame-r-004849-4-0794.fits', 'frame-r-000756-1-0653.fits', 'frame-r-003705-3-0401.fits', 'frame-r-003647-6-0134.fits', 'frame-r-001462-2-0374.fits', 'frame-r-005636-5-0082.fits', 'frame-r-003704-1-0134.fits', 'frame-r-005140-4-0074.fits', 'frame-r-001140-1-0273.fits', 'frame-r-005045-4-0141.fits', 'frame-r-004599-3-0084.fits', 'frame-r-004512-3-0256.fits', 'frame-r-004678-6-0077.fits', 'frame-r-002188-3-0153.fits', 'frame-r-004207-4-0162.fits', 'frame-r-004599-6-0152.fits', 'frame-r-005194-5-0390.fits', 'frame-r-004646-2-0179.fits', 'frame-r-007907-6-0145.fits', 'frame-r-004633-4-0020.fits', 'frame-r-002248-5-0055.fits', 'frame-r-004822-2-0246.fits', 'frame-r-002305-3-0152.fits', 'frame-r-003600-2-0030.fits', 'frame-r-004516-2-0189.fits', 'frame-r-004623-5-0190.fits', 'frame-r-000756-4-0798.fits', 'frame-r-003964-4-0115.fits', 'frame-r-003900-3-0550.fits', 'frame-r-001462-3-0047.fits', 'frame-r-002074-6-0103.fits', 'frame-r-006354-3-0296.fits', 'frame-r-003893-2-0116.fits', 'frame-r-003893-1-0106.fits', 'frame-r-003462-4-0042.fits', 'frame-r-002830-6-0192.fits', 'frame-r-002076-5-0161.fits', 'frame-r-003644-3-0184.fits', 'frame-r-002391-3-0037.fits', 'frame-r-003842-6-0082.fits', 'frame-r-005183-3-0389.fits', 'frame-r-003900-2-0256.fits', 'frame-r-005326-4-0045.fits', 'frame-r-004002-2-0284.fits', 'frame-r-003910-3-0175.fits', 'frame-r-003644-5-0188.fits', 'frame-r-006122-5-0049.fits', 'frame-r-006573-1-0202.fits', 'frame-r-003927-4-0049.fits', 'frame-r-004204-4-0112.fits', 'frame-r-007674-2-0033.fits', 'frame-r-004843-3-0123.fits', 'frame-r-007780-3-0084.fits', 'frame-r-001729-4-0039.fits', 'frame-r-007757-1-0041.fits', 'frame-r-001889-5-0062.fits', 'frame-r-003180-4-0090.fits', 'frame-r-003909-4-0105.fits', 'frame-r-008116-3-0324.fits', 'frame-r-003705-3-0144.fits', 'frame-r-007865-3-0209.fits', 'frame-r-008097-6-0034.fits', 'frame-r-002248-5-0229.fits', 'frame-r-004649-4-0171.fits', 'frame-r-001462-3-0412.fits', 'frame-r-001331-4-0156.fits', 'frame-r-008149-3-0203.fits', 'frame-r-005065-1-0083.fits', 'frame-r-003063-2-0043.fits', 'frame-r-007713-2-0280.fits', 'frame-r-005194-4-0698.fits', 'frame-r-003813-1-0098.fits', 'frame-r-008056-2-0056.fits', 'frame-r-004518-4-0027.fits', 'frame-r-008096-2-0073.fits', 'frame-r-003530-4-0301.fits', 'frame-r-003059-6-0046.fits', 'frame-r-003712-1-0098.fits', 'frame-r-002243-1-0382.fits', 'frame-r-008061-6-0025.fits', 'frame-r-001339-5-0070.fits', 'frame-r-002830-1-0113.fits', 'frame-r-002830-1-0085.fits', 'frame-r-003180-3-0138.fits', 'frame-r-004633-2-0072.fits', 'frame-r-002207-5-0023.fits']\n",
      "../data/temp/registered-r-005360-2-0181.list\n",
      "registered-r-005360-2-0181.sex\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-58770f45406b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun_online_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"../data/DR12_spec_phot_sample_thrush2.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-d0478fa7b696>\u001b[0m in \u001b[0;36mrun_online_mode\u001b[1;34m(filename, chunk_size)\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[0mconvert_catalog_to_pixels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pretty pretty pixels\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         \u001b[0mcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_sex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"so sexy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-d0478fa7b696>\u001b[0m in \u001b[0;36mrun_sex\u001b[1;34m(df, dirname)\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sex\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-c\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ls\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-l\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \"\"\"\n\u001b[1;32m--> 533\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[0;32m    846\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    849\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m             \u001b[1;31m# Cleanup if the child failed starting.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[0;32m   1444\u001b[0m                             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m                                 \u001b[0merr_msg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m': '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_executable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1446\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1447\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sex'"
     ]
    }
   ],
   "source": [
    "run_online_mode(filename = \"../data/DR12_spec_phot_sample_thrush2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
